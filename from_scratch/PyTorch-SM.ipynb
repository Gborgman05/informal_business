{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> &uarr;   Ensure Kernel is set to  &uarr;  </div><br><div style=\"text-align: right\"> \n",
    "conda_python3  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Estimator Bring your own Script\n",
    "\n",
    "In this notebook we will go through and run a PyTorch model to classify the junctions as priority, signal and roundabout as seen in data prep.\n",
    "\n",
    "The outline of this notebook is \n",
    "\n",
    "1. to prepare a training script (provided).\n",
    "\n",
    "2. use the AWS provided PyTorch container and provide our script to it.\n",
    "\n",
    "3. Run training.\n",
    "\n",
    "4. deploy model to end point.\n",
    "\n",
    "5. Test using an image in couple of possible ways "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrade Sagemaker so we can access the latest containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the libraries and set up the initial variables we will be using in this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "ON_SAGEMAKER_NOTEBOOK = False\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "if ON_SAGEMAKER_NOTEBOOK:\n",
    "    role = sagemaker.get_execution_role()\n",
    "else:\n",
    "    role = \"arn:aws:iam::099295524168:role/service-role/AmazonSageMaker-ExecutionRole-20220209T134488\"\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"dxhub-svvsd-labeled-images\"\n",
    "# key = \"data-folder\"   (in case you structure your data as your-bucket/data-folder) \n",
    "training_data_uri=\"s3://{}\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Estimator\n",
    "\n",
    "Use AWS provided open source containers, these containers can be extended by starting with the image provided by AWS and the add additional installs in dockerfile\n",
    "\n",
    "or you can use requirements.txt in source_dir to install additional libraries.\n",
    "\n",
    "Below code is for PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='ptModelCode.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.8',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    py_version='py3',\n",
    "                    # available hyperparameters: emsize, nhid, nlayers, lr, clip, epochs, batch_size,\n",
    "                    #                            bptt, dropout, tied, seed, log_interval\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the estimators fit method with the URI location of the training data to start the training <br>\n",
    "**Note:** This cell takes approximately **20 mins** to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-13 18:45:01 Starting - Starting the training job...\n",
      "2022-10-13 18:45:30 Starting - Preparing the instances for trainingProfilerReport-1665686701: InProgress\n",
      ".........\n",
      "2022-10-13 18:46:58 Downloading - Downloading input data......\n",
      "2022-10-13 18:48:03 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:05,463 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:05,465 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:05,475 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:05,482 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:05,984 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:05,998 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:06,008 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-13 18:48:06,016 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-10-13-18-45-00-645\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-099295524168/pytorch-training-2022-10-13-18-45-00-645/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"ptModelCode\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"ptModelCode.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=ptModelCode.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=ptModelCode\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-099295524168/pytorch-training-2022-10-13-18-45-00-645/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-10-13-18-45-00-645\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-099295524168/pytorch-training-2022-10-13-18-45-00-645/source/sourcedir.tar.gz\",\"module_name\":\"ptModelCode\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"ptModelCode.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 ptModelCode.py\u001b[0m\n",
      "\u001b[34mstarting in main\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:09.165 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:09.507 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:09.508 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:09.508 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:09.509 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:09.509 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.417 algo-1:26 INFO hook.py:591] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.417 algo-1:26 INFO hook.py:591] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.417 algo-1:26 INFO hook.py:591] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.2.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.2.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.418 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.2.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.2.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.3.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.3.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.419 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.2.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.2.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.3.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.3.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.420 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.4.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.4.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.5.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.5.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.421 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.2.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.2.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:fc.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:591] name:fc.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:593] Total Trainable Params: 21285698\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.422 algo-1:26 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-10-13 18:48:10.426 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mTrain loss 0.47622439649797255 accuracy 0.7840755735492577\u001b[0m\n",
      "\u001b[34mVal loss 0.6957116868760851 accuracy 0.615819209039548\u001b[0m\n",
      "\u001b[34m/opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mTrain loss 0.3974675721619078 accuracy 0.8272604588394062\u001b[0m\n",
      "\u001b[34mVal loss 0.7873117532995012 accuracy 0.5225988700564972\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTE:** <br>\n",
    "If at this point your kernel disconnects from the server (you can tell because the kernel in the top right hand corner will say **No Kernel**),<br>you can reattach to the training job (so you dont to start the training job again).<br>Follow the steps below\n",
    "1. Scoll your notebook to the top and set the kernel to the recommended kernel specified in the top right hand corner of the notebook\n",
    "2. Go to your SageMaker console, Go to Training Jobs and copy the name of the training job you were disconnected from\n",
    "3. Scoll to the bottom of this notebook, paste your training job name to replace the **your-training-job-name** in the cell\n",
    "4. Replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook\n",
    "5. Run the edited cell\n",
    "6. Return to this cell and continue executing the rest of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the model_data method on the estimator to find the location of the trained model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model_data\n",
    "latest_model = estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-099295524168/pytorch-training-2022-10-13-18-45-00-645/output/model.tar.gz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploying a model\n",
    "Once trained, deploying a model is a simple call.\n",
    "\n",
    "**Note:** Replace the **'your_model_uri'** with the URI from the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "pytorch_model = PyTorchModel(model_data=latest_model, \n",
    "                             role=role, \n",
    "                             entry_point='ptInfCode.py', \n",
    "                             framework_version='1.7',\n",
    "                             py_version='py3')\n",
    "predictor = pytorch_model.deploy(instance_type='ml.m5.2xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the endpoint name from predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-inference-2022-10-13-22-53-20-516\n"
     ]
    }
   ],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our endpoint is up and running, lets test it with all of our unseen images and see how well it does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "test_files=[]\n",
    "response = s3_client.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Prefix='test'\n",
    ")\n",
    "for item in response['Contents']:\n",
    "    test_files.append(item['Key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "s3 = boto3.resource('s3', region_name='us-west-2')\n",
    "s3_bucket = s3.Bucket(bucket)\n",
    "\n",
    "endpoint_name = predictor.endpoint_name\n",
    "\n",
    "# image category, fight probabily, no fight probability\n",
    "inference_data = []\n",
    "\n",
    "for file_object in test_files:\n",
    "    #print(file_object)\n",
    "    object = s3_bucket.Object(file_object)\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "\n",
    "    with open(tmp.name, 'wb') as f:\n",
    "        object.download_fileobj(f)\n",
    "    \n",
    "    # whatever you need to do\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/x-image',\n",
    "        Body=open(tmp.name, 'rb').read())\n",
    "    result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "    inf_data_row = [file_object.split('/')[1], result[0]['Fight'], result[0]['No Fight']]\n",
    "    inference_data.append(inf_data_row)\n",
    "\n",
    "df = pd.DataFrame(inference_data, columns=['Category','FProb','NoFProb'])\n",
    "\n",
    "# clean up inference instance\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us view the JSON response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled fights: 172 Labeled No Fights: 600\n",
      "True Positive: 121 True Negative: 556 False Negative: 51 False Positive: 44\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.7034883720930233\n",
      "Accuracy: 0.8769430051813472\n"
     ]
    }
   ],
   "source": [
    "POS_THRESHHOLD = 0.213\n",
    "NEG_THRESHHOLD = 0.735\n",
    "\n",
    "# convert probabilities to float\n",
    "df['FProb'] = pd.to_numeric(df['FProb'], errors='coerce')\n",
    "df['NoFProb'] = pd.to_numeric(df['NoFProb'], errors='coerce')\n",
    "\n",
    "# separate frames into fight and no labeled photos\n",
    "fight_fl = df['Category']=='Fight'\n",
    "no_fight_fl = df['Category']=='No Fight'\n",
    "\n",
    "fight_df = df[fight_fl]\n",
    "no_fight_df = df[no_fight_fl]\n",
    "\n",
    "fight_detected_fl = fight_df['FProb']>=POS_THRESHHOLD\n",
    "fight_detected_df = fight_df[fight_detected_fl]\n",
    "\n",
    "no_fight_detected_fl = no_fight_df['NoFProb']>=NEG_THRESHHOLD\n",
    "no_fight_detected_df = no_fight_df[no_fight_detected_fl]\n",
    "\n",
    "true_positive = fight_detected_df['Category'].count()\n",
    "true_negative = no_fight_detected_df['Category'].count()\n",
    "false_positive = no_fight_df['Category'].count()-true_negative\n",
    "false_negative = fight_df['Category'].count()-true_positive\n",
    "\n",
    "print(\"Labeled fights:\", fight_df['Category'].count(), \"Labeled No Fights:\", no_fight_df['Category'].count())\n",
    "print(\"True Positive:\",true_positive,\"True Negative:\",true_negative, \"False Negative:\",false_negative, \"False Positive:\",false_positive)\n",
    "\n",
    "print(\"Precision:\",true_positive/(true_positive+false_positive))\n",
    "print(\"Recall:\",true_positive/(true_positive+false_negative))\n",
    "print(\"Accuracy:\",(true_positive+true_negative)/(df['Category'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 226)\n",
    "no_fight_df\n",
    "no_fight_detected_df.count()\n",
    "fight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to a training job that has been left to run \n",
    "\n",
    "If your kernel becomes disconnected and your training has already started, you can reattach to the training job.<br>\n",
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook<br>\n",
    "Simply look up the training job name and replace the **your-training-job-name** and then run the cell below. <br>\n",
    "Once the training job is finished, you can continue the cells after the training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "bucket = \"your-unique-bucket-name\"\n",
    "\n",
    "training_job_name = 'your-training-job-name'\n",
    "\n",
    "if 'your-training' not in training_job_name:\n",
    "    estimator = sagemaker.estimator.Estimator.attach(training_job_name=training_job_name, sagemaker_session=sess)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
